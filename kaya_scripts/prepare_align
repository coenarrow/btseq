#!/bin/bash

# Check if an output directory argument is passed, otherwise use the current directory
if [ -z "$1" ]; then
    outdir=$(pwd)
else
    outdir="$1"
fi

# Set the path to the input file containing definitions
defs="BSTarget_input.txt"

# Create the "Run" directory inside the output directory
mkdir -p "${outdir}/Run"

# Create a new file for the batch script and set it as executable
touch "${outdir}/Run/Run.q"
chmod +x "${outdir}/Run/Run.q"

# Add the shebang line to specify the shell interpreter
echo '#! /bin/bash' >> "${outdir}/Run/Run.q"

# Read through each line of the input file and process the fields
cat "$defs" | awk -v d="${outdir}" '
{
    # Define the output script for each task
    Qout=d "/Run/" $2 "_" $1 ".q";

    # Generate the task script for each entry in the input file
    print "touch " d "/Run/" $2 "_" $1 ".q";
    print "echo \047\043\\! /bin/bash\047 >> " Qout;
    print "echo echo \\$HOSTNAME >> " Qout;  # Print the hostname
    print "echo mkdir " d "/" $2 "_" $1 " >> " Qout;  # Create a directory for the task
    print "echo cp -s " $4 " " d "/" $2 "_" $1 " >> " Qout;  # Create symbolic links to input files
    print "echo module load bioinfo >> " Qout;  # Load bioinfo module (necessary for bioinformatics tools)
    print "echo module load bio >> " Qout;  # Load additional bio module
    print "echo bismark_genome_preparation --bowtie2 " d "/" $2 "_" $1 " >> " Qout;  # Prepare the genome using bismark (a tool for aligning bisulfite-treated sequences)
    print "echo bismark " d "/" $2 "_" $1 " " $3 " --sam --bowtie2 -o " d "/" $2 "_" $1 "/Output --temp_dir " d "/" $2 "_" $1 "/Output >> " Qout;  # Run the bismark alignment
    print "echo /cs/icore/joshua.moss/scripts/btseq/Analyze_Result.csh " $3 " " d "/" $2 "_" $1 " >> " Qout;  # Call a custom analysis script
    print "echo sbatch --mem=4GB --cpus-per-task=3 --time=5:00:00 --output=" d "/Run/" $2 "_" $1 ".q.out " d "/Run/" $2 "_" $1 ".q >> " d "/Run/Run.q";  # Submit the job using Slurm
}' >& /dev/null

# After generating the scripts, you can manually run the following commands to compress results:
# 1. Sort the results by the second column and find unique entries.
# 2. Zip the results based on unique entries and include summary and hist files (e.g., summary statistics and histograms).

# Example compression process (uncomment if needed):
# for n in $(awk '{print $2}' Def.txt | sort | uniq); do
#     zip ${n}_Results $(du -a | grep -P 'summary$|hist$' | grep ${n} | awk '{print $2}')
# done
